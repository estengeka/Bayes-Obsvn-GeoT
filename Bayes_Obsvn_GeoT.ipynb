{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCYuKN7Nb3rk2H00Et92q5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4eb018a"
      },
      "source": [
        "# Bayesian Updating for Observational Method in Geotechnical Engineering\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The observational method in geotechnical engineering involves monitoring performance during construction to adjust designs based on actual behavior, reducing conservatism and costs. Originated by Terzaghi and refined by Peck (1969), it allows for adaptive management in projects like foundations, slopes, and dams.\n",
        "\n",
        "Bayesian updating enhances this by incorporating uncertainty probabilistically. It starts with prior distributions of soil parameters (e.g., from site investigations) and updates them to posteriors using new data (likelihood), via Bayes' theorem: P(θ|data) ∝ P(data|θ) * P(θ).\n",
        "\n",
        "This integration addresses an unsolved challenge: lack of seamless, automated tools for real-time parameter updating during construction, leading to suboptimal risk management. Research value includes improved safety and efficiency in adaptive designs, e.g., for climate-resilient infrastructure.\n",
        "\n",
        "Example scenario: Updating undrained shear strength (Su) of clay soil during pile foundation construction. Prior from initial borings: Su ~ Normal(50 kPa, 10 kPa). Sequential cone penetration test (CPT) data during installation provides observations, assumed ~ Normal(Su, 5 kPa noise). We update posteriors, compute P(Su < 40 kPa) for failure risk, and suggest adjustments if risk > 5%.\n",
        "\n",
        "References: Tang (1979) on probabilistic observational method; Straub (2010) on Bayesian geotechnics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cea2e92"
      },
      "source": [
        "# Setup and Libraries\n",
        "# Install required packages (PyMC and Arviz may not be pre-installed in Colab)\n",
        "!pip install pymc arviz -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "from google.colab import files\n",
        "import io\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from scipy.stats import norm  # For analytical checks, optional\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb3bb2e1"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "We simulate synthetic data for demonstration. Prior: Su ~ Normal(50, 10) kPa.\n",
        "\n",
        "Observations: 10 sequential CPT measurements from a \"true\" Su=45 kPa with noise (std=5 kPa).\n",
        "\n",
        "Data stored in Pandas DataFrame.\n",
        "\n",
        "For real data: Upload a CSV with column 'observations' (one value per row)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d6e1aa0"
      },
      "source": [
        "# Simulate prior samples (for visualization)\n",
        "prior_samples = np.random.normal(50, 10, 1000)\n",
        "\n",
        "# Simulate observational data\n",
        "true_su = 45  # Hidden true value for simulation\n",
        "num_observations = 10\n",
        "observation_std = 5\n",
        "observations = np.random.normal(true_su, observation_std, num_observations)\n",
        "\n",
        "# Store in DataFrame\n",
        "data_df = pd.DataFrame({'observations': observations})\n",
        "print(\"Simulated Observations:\")\n",
        "print(data_df)\n",
        "\n",
        "# Option for user-uploaded data (commented; uncomment to use)\n",
        "# uploaded = files.upload()\n",
        "# if uploaded:\n",
        "#     data_df = pd.read_csv(io.BytesIO(uploaded[list(uploaded.keys())[0]]))\n",
        "#     observations = data_df['observations'].values\n",
        "#     num_observations = len(observations)\n",
        "#     print(\"Uploaded Data Loaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78f5aee"
      },
      "source": [
        "## Bayesian Model Implementation\n",
        "\n",
        "We use PyMC for hierarchical Bayesian modeling.\n",
        "\n",
        "Model:\n",
        "- Prior: Su ~ Normal(mu_prior, sigma_prior)\n",
        "- Likelihood: obs[i] ~ Normal(Su, sigma_obs)\n",
        "\n",
        "For sequential updating, we'll define a function to run MCMC on cumulative data.\n",
        "\n",
        "Compute posterior samples, 95% HDI, and risk P(Su < 40).\n",
        "\n",
        "Adaptive decision: If risk > 0.05, suggest adjustment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ec887a"
      },
      "source": [
        "# Define a function for the Bayesian model\n",
        "def bayesian_update_model(cumulative_obs, mu_prior=50, sigma_prior=10, sigma_obs=5):\n",
        "    with pm.Model() as model:\n",
        "        # Prior\n",
        "        su = pm.Normal('su', mu=mu_prior, sigma=sigma_prior)\n",
        "\n",
        "        # Likelihood\n",
        "        obs = pm.Normal('obs', mu=su, sigma=sigma_obs, observed=cumulative_obs)\n",
        "\n",
        "        # Sample posterior (MCMC)\n",
        "        trace = pm.sample(1000, tune=500, return_inferencedata=True, progressbar=False)\n",
        "\n",
        "    return trace\n",
        "\n",
        "# Initial prior (no data)\n",
        "initial_trace = bayesian_update_model([])  # Empty obs for prior only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0fba90e"
      },
      "source": [
        "## Sequential Updating Loop\n",
        "\n",
        "Iteratively update with cumulative observations.\n",
        "\n",
        "Collect posteriors and risks at each step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1e08bac"
      },
      "source": [
        "# Sequential updating\n",
        "posterior_traces = [initial_trace]  # Start with prior\n",
        "risks = []  # P(su < 40)\n",
        "threshold = 40\n",
        "risk_tolerance = 0.05\n",
        "\n",
        "cumulative_obs = []\n",
        "for i in range(num_observations):\n",
        "    cumulative_obs.append(observations[i])\n",
        "    trace = bayesian_update_model(np.array(cumulative_obs))\n",
        "    posterior_traces.append(trace)\n",
        "\n",
        "    # Compute risk\n",
        "    su_samples = trace.posterior['su'].values.flatten()\n",
        "    risk = np.mean(su_samples < threshold)\n",
        "    risks.append(risk)\n",
        "\n",
        "    # Adaptive decision\n",
        "    if risk > risk_tolerance:\n",
        "        print(f\"After {i+1} observations: Risk = {risk:.3f} > {risk_tolerance}. Suggest design adjustment (e.g., add piles).\")\n",
        "    else:\n",
        "        print(f\"After {i+1} observations: Risk = {risk:.3f} <= {risk_tolerance}. Proceed.\")\n",
        "\n",
        "# Include initial risk from prior\n",
        "initial_su_samples = initial_trace.posterior['su'].values.flatten()\n",
        "initial_risk = np.mean(initial_su_samples < threshold)\n",
        "risks.insert(0, initial_risk)\n",
        "print(f\"Initial Risk (Prior): {initial_risk:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a6d26c2"
      },
      "source": [
        "## Visualization and Analysis\n",
        "\n",
        "Plot prior vs. posteriors.\n",
        "\n",
        "Trace plots for last update.\n",
        "\n",
        "Evolving risk plot.\n",
        "\n",
        "Interactive: Vary number of observations with widget."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c6a32a8"
      },
      "source": [
        "# Plot prior vs final posterior\n",
        "fig, ax = plt.subplots()\n",
        "az.plot_posterior(initial_trace, var_names=['su'], ax=ax, color='blue', label='Prior')\n",
        "az.plot_posterior(posterior_traces[-1], var_names=['su'], ax=ax, color='green', label='Final Posterior')\n",
        "plt.title('Prior vs Final Posterior for Su')\n",
        "plt.xlabel('Su (kPa)')\n",
        "plt.show()\n",
        "\n",
        "# Trace plot for final model (convergence check)\n",
        "az.plot_trace(posterior_traces[-1], var_names=['su'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "171539c9"
      },
      "source": [
        "# Evolving risk plot\n",
        "plt.plot(range(len(risks)), risks, marker='o')\n",
        "plt.axhline(risk_tolerance, color='red', linestyle='--', label='Tolerance')\n",
        "plt.title('Evolving Failure Risk P(Su < 40 kPa)')\n",
        "plt.xlabel('Number of Observations')\n",
        "plt.ylabel('Probability')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56c81b37"
      },
      "source": [
        "# Interactive: Vary number of observations\n",
        "def plot_posterior_up_to(n_obs):\n",
        "    if n_obs == 0:\n",
        "        trace = initial_trace\n",
        "    else:\n",
        "        trace = posterior_traces[n_obs]\n",
        "\n",
        "    az.plot_posterior(trace, var_names=['su'])\n",
        "    plt.title(f'Posterior after {n_obs} Observations')\n",
        "    plt.show()\n",
        "\n",
        "    su_samples = trace.posterior['su'].values.flatten()\n",
        "    risk = np.mean(su_samples < threshold)\n",
        "    print(f\"Risk: {risk:.3f}\")\n",
        "\n",
        "widgets.interact(plot_posterior_up_to, n_obs=(0, num_observations, 1));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84b07ef6"
      },
      "source": [
        "## Real-Time Simulation\n",
        "\n",
        "Mimic real-time data stream with a loop (e.g., \"receiving\" data every few seconds).\n",
        "\n",
        "In practice, integrate with IoT sensors via APIs (e.g., stream CPT data to Colab via Google Drive or external service)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbd97602"
      },
      "source": [
        "# Real-time simulation (loop with delays)\n",
        "import time\n",
        "\n",
        "# Reset for demo\n",
        "cumulative_obs_rt = []\n",
        "rt_trace = initial_trace\n",
        "for i in range(num_observations):\n",
        "    cumulative_obs_rt.append(observations[i])\n",
        "    rt_trace = bayesian_update_model(np.array(cumulative_obs_rt))\n",
        "\n",
        "    su_samples = rt_trace.posterior['su'].values.flatten()\n",
        "    risk = np.mean(su_samples < threshold)\n",
        "    print(f\"Real-time Update {i+1}: Risk = {risk:.3f}\")\n",
        "\n",
        "    time.sleep(1)  # Simulate delay between measurements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79a5cb25"
      },
      "source": [
        "## Extensions and Research Discussion\n",
        "\n",
        "Extensions:\n",
        "- Multi-parameter: Update Su, modulus, etc., with multivariate normals.\n",
        "- Spatial variability: Incorporate Gaussian processes (via PyMC).\n",
        "- FEM integration: Export posteriors to PLAXIS/ABAQUS via Python APIs for simulations.\n",
        "- Large-scale: Use variational inference for speed on big data.\n",
        "\n",
        "Limitations: MCMC slow for thousands of data points; switch to conjugate analytics for simples cases.\n",
        "\n",
        "This prototypes real-time adaptive risk tools, addressing unsolved integration of observations with probabilistics—ideal for PhD research or conference (e.g., GeoRisk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1cda485"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "This notebook demonstrates Bayesian updating in the observational method, enabling adaptive geotechnical designs. It shows sequential refinement of soil parameters and risk, paving the way for automated tools in construction monitoring."
      ]
    }
  ]
}